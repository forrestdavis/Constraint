{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7903dbbb-14db-452d-bfc4-aba8b4840cf3",
   "metadata": {},
   "source": [
    "# HW 4: Character-level RNN Language Modeling \n",
    "#### COSC 410: Spring 2024, Colgate University\n",
    "\n",
    "In this homework you will be working with language data.\n",
    "\n",
    "## Task\n",
    "\n",
    "Your task is to build a character-level RNN language model. For debugging purposes, a small plain text file called `red_riding_hood.txt` is included. Once you have set up the pipeline, you should consider the `train.txt`, `valid.txt`, and `test.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ebc0b-bc4a-4a0e-8c28-aa9e59b155d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some helpful packages \n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194a7a1-4b11-42bc-810d-998f1de3d11c",
   "metadata": {},
   "source": [
    "## Part 0: Thinking through the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd149c-6829-47d9-9278-12f1ccf9448a",
   "metadata": {},
   "source": [
    "How is this model going to be different from the model in lab? What are you predicting, what has to change in your model, etc? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d0fcd-b797-48a7-8881-cc6f4f7843e2",
   "metadata": {},
   "source": [
    "[**Written Answer**]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d9d38-1a68-4782-9f62-c6a050284721",
   "metadata": {},
   "source": [
    "## Part 1: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94dbdf-d16d-457d-8bbd-74cb5e9cbaba",
   "metadata": {},
   "source": [
    "[**Code Answer**] In this section, load your data, chunk it into sequence lengths, and one-hot encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65771867-f4dd-45d6-9943-9213ea33fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str): \n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read().replace('\\n', ' ').lower()\n",
    "    return text\n",
    "\n",
    "def get_vocab(text: str):\n",
    "    unique_chars = set(text)\n",
    "    mapping = {}\n",
    "    idx = 0\n",
    "    for char in unique_chars:\n",
    "        mapping[char] = idx\n",
    "        idx += 1\n",
    "    return mapping\n",
    "\n",
    "def sequence(text: str, seqLen:int) -> np.array: \n",
    "    \"\"\"Make sequence length chunks of continguous text \"\"\"\n",
    "    data = []\n",
    "    for i in range(0, len(text)-seqLen, seqLen):\n",
    "        data.append(text[i:i+seqLen])\n",
    "    return np.array(data)\n",
    "\n",
    "def encode_data(data, mapping: dict): \n",
    "    \"\"\" You implement \"\"\"\n",
    "    pass\n",
    "\n",
    "def decode_data(data, mapping: dict):\n",
    "    \"\"\" You implement \"\"\" \n",
    "    # Reverse mapping \n",
    "    pass\n",
    "\n",
    "text = load_data('train.txt')\n",
    "mapping = get_vocab(text)\n",
    "data = sequence(text, 40)\n",
    "# This assert should work if you've done things correctly\n",
    "assert (data == decode_data(encode_data(data, mapping), mapping)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40263360-5d88-4c10-a78a-e7aca1f01c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensors and one hot\n",
    "def oneHot(data: np.array, mapping: dict) -> torch.tensor:\n",
    "    \"\"\" You implement \"\"\"\n",
    "    pass\n",
    "\n",
    "def unHot(data: torch.tensor, mapping: dict) -> np.array:\n",
    "    \"\"\" You implement \"\"\"\n",
    "    pass\n",
    "\n",
    "# This assert should work\n",
    "assert (data == decode_data(unHot(oneHot(encode_data(data, mapping), mapping), mapping),mapping)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674548a-9c04-4cc2-bbe4-fe490f42e7f1",
   "metadata": {},
   "source": [
    "## Part 2: Build a RNN\n",
    "\n",
    "[**Code Answer**] In this section, build an RNN class for a character-level RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb35ad5-2f18-462a-9a89-094cc1e8ff43",
   "metadata": {},
   "source": [
    "## Part 3: Train\n",
    "\n",
    "[**Code Answer**] In this section, implement a train function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b977cb-6663-4c70-ad58-3d38d3346c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data and set up y\n",
    "fname = 'train.txt'\n",
    "sequenceLength = 50\n",
    "text = load_data(fname)\n",
    "mapping = get_vocab(text)\n",
    "data = oneHot(encode_data(sequence(text, sequenceLength), mapping), mapping)\n",
    "\n",
    "# Find input/output \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71063756-99d1-462f-abed-7b9856bea6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInput = X.shape[-1]\n",
    "nHidden = 512\n",
    "nLayers = 3\n",
    "batchSize = 50\n",
    "nEpochs = 2\n",
    "lr = 0.1\n",
    "model = RNNModel(nInput, nHidden, nLayers)\n",
    "train(X, Y, model, nEpochs, batchSize, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6cb64-6f72-49de-9c74-c246bd4dc62c",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bf856-d540-4d79-ae32-0f6761e8b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, outname):\n",
    "    torch.save(model, outname)\n",
    "\n",
    "def load(filename):\n",
    "    return torch.load(filename)\n",
    "\n",
    "modelName = 'draculaRNN.pt'\n",
    "save(model, modelName)\n",
    "model = load(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4031c182-e79e-4a96-99e6-127249f013c9",
   "metadata": {},
   "source": [
    "## Part 4: Evaluate your model\n",
    "\n",
    "[**Code Answer**] Evaluate your model on valid data, tuning the hyperparameters to get a better model. Once you have a model tuned, evaluate it on test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333984cd-795d-4940-a5ca-2718666da544",
   "metadata": {},
   "source": [
    "[**Written Answer**] Look at the data split, and reflect (in your response) on what differentiates `test.txt` from `train.txt` and `valid.txt` (NOTE: `valid.txt` contains the final chapter of Dracula). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2d400-b325-4cd4-a64d-882957d75799",
   "metadata": {},
   "source": [
    "## Part 5: Generate\n",
    "\n",
    "[**Code Answer**] Play around with your model's ability to generate language data using the `generate` function below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91140a1d-fece-4d90-b768-0649d9c9664a",
   "metadata": {},
   "source": [
    "[**Written Answer**] Explain in bullet points how `generate` works, experiment with different prefixes, and play with different temperatures so you can explain what temperature means (at a high level). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50e124-ed4a-474d-a24a-2b50d6c7b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, mapping, prefix, num_chars, temperature):\n",
    "    model.eval()\n",
    "    result = prefix.lower()\n",
    "    \n",
    "    X = oneHot(encode_data([result], mapping), mapping)\n",
    "    \n",
    "    hidden = model.init_hidden(1)\n",
    "    logits, hidden = model(X, hidden)\n",
    "\n",
    "    for i in range(num_chars):\n",
    "        dist = torch.distributions.Categorical(logits=logits[:,-1,:] / temperature)\n",
    "        prediction = dist.sample()\n",
    "        prediction = prediction[None, :]\n",
    "\n",
    "        char = decode_data(prediction.numpy(), mapping)[0]\n",
    "        result += char\n",
    "\n",
    "        X = oneHot(prediction, mapping)\n",
    "        logits, hidden = model(X, hidden)\n",
    "    return result\n",
    "\n",
    "print(generate(model, mapping, 'To stop and see people', 100, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
